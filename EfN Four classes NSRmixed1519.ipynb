{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a41ffe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import json\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5c4522",
   "metadata": {},
   "source": [
    "os: The os library, as introduced earlier, allows us to interact with the operating system. It helps us manage file paths, directories, and other system-related operations efficiently.\n",
    "\n",
    "cv2: OpenCV (cv2) is a powerful library for computer vision and image processing tasks. Its inclusion in our program signifies our exploration into visual data analysis and manipulation.\n",
    "\n",
    "json: JSON (JavaScript Object Notation) is a lightweight data interchange format. By incorporating the json library, we are equipped to handle data in JSON format and perform related operations.\n",
    "\n",
    "pathlib: As discussed previously, pathlib offers a more object-oriented approach to handle file paths and directories, providing a robust and platform-independent solution.\n",
    "\n",
    "numpy (np): NumPy is the fundamental package for scientific computing with Python. It enables efficient numerical computations, particularly with arrays and matrices.\n",
    "\n",
    "pandas (pd): Pandas, already introduced, plays a central role in data manipulation, organization, and analysis. Its versatile DataFrames help us process and explore data with ease.\n",
    "\n",
    "tensorflow (tf): TensorFlow is an open-source machine learning framework that enables us to build and train deep learning models, opening the door to powerful predictive and analytical capabilities.\n",
    "\n",
    "matplotlib.pyplot (plt): Matplotlib is a comprehensive library for creating static, interactive, and animated visualizations in Python. The pyplot module enables us to generate a wide range of plots and charts to visualize our data effectively.\n",
    "\n",
    "PIL (Image): The Python Imaging Library (PIL) provides image processing capabilities, enabling us to work with images in various formats.\n",
    "\n",
    "datetime (dt): The datetime module allows us to work with date and time data efficiently, which is particularly useful when dealing with temporal aspects in our ECG record analysis.\n",
    "\n",
    "By incorporating these additional libraries, we expand the scope of our Python program to encompass image processing, machine learning, JSON data handling, and advanced visualization. As we progress further, these powerful tools will enhance our ability to draw deeper insights from the ECG records and enable us to present our findings in visually compelling ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9851bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import mobilenet_v3\n",
    "from tensorflow.keras.layers import Dense,GlobalMaxPooling2D\n",
    "from tensorflow.keras.optimizers import RMSprop, Adadelta\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917c1e8c",
   "metadata": {},
   "source": [
    "tensorflow.keras: TensorFlow 2.0 introduced the Keras API as the official high-level API for deep learning. The integration of tensorflow.keras enables us to access and utilize various pre-built models, layers, optimizers, and data augmentation utilities seamlessly.\n",
    "\n",
    "Model: The Model class from tensorflow.keras allows us to build our custom neural network models, combining layers and creating complex architectures to suit our specific requirements.\n",
    "\n",
    "layers: TensorFlow and Keras provide a wide range of built-in layers for building neural networks. We can use layers like convolutional, pooling, dense, and more to construct sophisticated models.\n",
    "\n",
    "mobilenet_v3: MobileNetV3 is a popular pre-trained model for image classification tasks. By utilizing mobilenet_v3, we can leverage its powerful features to perform image-based tasks effectively.\n",
    "\n",
    "Dense and GlobalMaxPooling2D: These are specific layers from Keras that play a significant role in defining the structure and functionality of our neural network models.\n",
    "\n",
    "RMSprop and Adadelta: These are optimization algorithms that can be used to train our deep learning models efficiently.\n",
    "\n",
    "ImageDataGenerator: The ImageDataGenerator class simplifies the process of loading, preprocessing, and augmenting image data during model training. It enhances our ability to work with image datasets and achieve better model generalization.\n",
    "\n",
    "By integrating TensorFlow and Keras into our Python program, we lay the foundation for powerful deep learning models that can discern patterns, classify images, and even aid in predicting heart-related conditions based on ECG records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7af33a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "tf.test.is_built_with_cuda()\n",
    "print(\"Num GPUs Available: \", len(device_lib.list_local_devices()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca60e8d",
   "metadata": {},
   "source": [
    "from tensorflow.python.client import device_lib: This import allows us to access the device_lib module, which provides information about the available devices, including GPUs.\n",
    "\n",
    "tf.test.is_built_with_cuda(): The is_built_with_cuda() function checks if TensorFlow was built with CUDA support, which is essential for GPU acceleration. CUDA is a parallel computing platform and programming model developed by NVIDIA for general-purpose computing on GPUs.\n",
    "\n",
    "device_lib.list_local_devices(): The list_local_devices() function returns a list of all local devices available for computation, including both CPUs and GPUs.\n",
    "\n",
    "Checking for GPU Availability:\n",
    "\n",
    "The first line of code checks if TensorFlow was built with CUDA support by calling tf.test.is_built_with_cuda(). This ensures that our TensorFlow installation is GPU-enabled, allowing us to take advantage of GPU acceleration.\n",
    "\n",
    "The second line, print(\"Num GPUs Available: \", len(device_lib.list_local_devices())), reports the number of GPUs available on the system. It does this by calling device_lib.list_local_devices() to get a list of all local devices, and then the length of this list corresponds to the number of GPUs available.\n",
    "\n",
    "The Significance of GPU Acceleration:\n",
    "When working with deep learning models, especially complex neural networks with large datasets, training can be computationally intensive. GPUs excel at parallel processing, making them highly effective for accelerating matrix operations and model training. Utilizing GPUs allows us to perform thousands of computations simultaneously, dramatically reducing the time required for model training and making it feasible to train complex models that would be infeasible on CPUs alone.The availability of GPUs empowers us to take full advantage of the hardware resources and supercharge our deep learning model training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53c5ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e3badf",
   "metadata": {},
   "source": [
    "IMG_SIZE: The IMG_SIZE parameter represents the desired image size used during data preprocessing and model training. It defines the width and height of the image in pixels. In this case, the IMG_SIZE is set to 224.\n",
    "\n",
    "batch_size: The batch_size parameter determines the number of samples processed in each training iteration. During model training, the data is divided into smaller batches, and the model updates its parameters based on the gradients computed for each batch. Setting an appropriate batch_size is crucial for optimizing memory usage and ensuring efficient utilization of hardware resources during training.\n",
    "\n",
    "The Impact of Image Size and Batch Size:\n",
    "\n",
    "Image Size (IMG_SIZE): The choice of IMG_SIZE can significantly impact both the model's performance and computational requirements. Smaller image sizes generally lead to faster training times but may sacrifice some fine-grained details in the images. Conversely, larger image sizes provide more detail to the model but might require more memory and computation during training.\n",
    "\n",
    "A common practice is to use power-of-two image sizes (e.g., 224, 256, 512) as they are more computationally efficient for modern deep learning frameworks and GPU accelerators.\n",
    "Batch Size: The batch_size parameter is crucial for optimizing model training. Choosing a batch size that is too large may lead to memory limitations, especially when working with GPUs that have limited memory capacity. Conversely, a batch size that is too small might lead to slower convergence and less efficient model training.\n",
    "\n",
    "A typical approach is to experiment with different batch sizes, starting with moderate values (e.g., 32, 64, 128) and adjusting as needed based on memory constraints and training performance.\n",
    "Optimizing the Hyperparameters:\n",
    "To optimize IMG_SIZE and batch_size for our ECG record image analysis, we need to consider factors such as available hardware resources (e.g., GPU memory), the size of the dataset, and the complexity of the deep learning model.\n",
    "\n",
    "It's advisable to experiment with different IMG_SIZE values and observe how they impact model performance and memory requirements.\n",
    "\n",
    "For batch_size, we can start with moderate values and gradually increase or decrease them based on how the model performs during training. Additionally, consider the trade-off between larger batch sizes (more efficient but memory-intensive) and smaller batch sizes (less efficient but memory-friendly).\n",
    "\n",
    "By carefully selecting the optimal values for IMG_SIZE and batch_size, we can strike a balance between model performance, training efficiency, and hardware utilization. These hyperparameters form a crucial part of our deep learning journey, guiding us towards achieving the best results in our ECG record analysis.We fine-tune our hyperparameters, uncover patterns in the ECG data, and witness the transformative power of deep learning in healthcare data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e912f4f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2421 files belonging to 4 classes.\n",
      "Using 1453 files for training.\n",
      "CPU times: total: 297 ms\n",
      "Wall time: 327 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_train=tf.keras.preprocessing.image_dataset_from_directory(\"D:\\\\ECG DB\\\\FourClassesWithNSRmixed1519\",\n",
    "                                                             labels='inferred',label_mode=\"int\",\n",
    "                                                             class_names=['AF','NSR','PAC','PVC'],color_mode='rgb',\n",
    "                                                             batch_size=batch_size,image_size=(IMG_SIZE,IMG_SIZE), #reshapeauto\n",
    "                                                             shuffle=True,seed=123,validation_split=0.4,subset=\"training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5148ece7",
   "metadata": {},
   "source": [
    "In our Python program, we have introduced the tf.keras.preprocessing.image_dataset_from_directory() function to prepare our image dataset for deep learning. Profiling the execution time of this function using the %%time magic command allows us to gain insights into the time taken to preprocess the dataset.\n",
    "\n",
    "%%time: The %%time magic command is a Jupyter Notebook feature that allows us to measure the execution time of a cell. When we execute the cell containing this magic command, it will report the time taken for the cell's execution.\n",
    "\n",
    "tf.keras.preprocessing.image_dataset_from_directory(): This function is a powerful utility provided by TensorFlow that automatically creates a labeled dataset from a directory containing image files. It performs data preprocessing, label encoding, and batching, all in one step, streamlining the process of preparing image data for model training.\n",
    "\n",
    "Dataset Preprocessing Parameters:\n",
    "\n",
    "\"D:\\\\ECG DB\\\\FourClassesWithNSRmixed1519\": The path to the directory containing our image dataset.\n",
    "\n",
    "labels='inferred': Inferred labels are derived from the directory structure, where each subdirectory represents a different class, and the subdirectory names are used as class labels.\n",
    "\n",
    "label_mode=\"int\": The labels are encoded as integers, corresponding to the class index.\n",
    "\n",
    "class_names=['AF', 'NSR', 'PAC', 'PVC']: The names of the classes present in the dataset.\n",
    "\n",
    "color_mode='rgb': The color mode of the images (RGB format).\n",
    "\n",
    "batch_size: The batch size used during training.\n",
    "\n",
    "image_size=(IMG_SIZE, IMG_SIZE): The desired size of the images for preprocessing.\n",
    "\n",
    "shuffle=True: Shuffles the data to introduce randomness during training.\n",
    "\n",
    "seed=123: The random seed used for shuffling the data.\n",
    "\n",
    "validation_split=0.4: Splits the dataset, reserving 40% for validation, and 60% for training.\n",
    "\n",
    "subset=\"training\": Specifies that we are creating a dataset for training purposes.\n",
    "\n",
    "Profiling the Execution Time:\n",
    "By using %%time before executing the cell, we can monitor the execution time of this particular dataset preprocessing step. The output will show us the time taken for the entire preprocessing process.\n",
    "\n",
    "The profiling information allows us to assess the efficiency of dataset preparation and gives us valuable insights into how much time this step takes. It helps us optimize our workflow and identify potential bottlenecks in our data pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce4a2408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2421 files belonging to 4 classes.\n",
      "Using 968 files for validation.\n",
      "CPU times: total: 234 ms\n",
      "Wall time: 235 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ds_validate=tf.keras.preprocessing.image_dataset_from_directory(\"D:\\\\ECG DB\\\\FourClassesWithNSRmixed1519\",\n",
    "                                                                labels='inferred',label_mode=\"int\",\n",
    "                                                                class_names=['AF','NSR','PAC','PVC'],color_mode='rgb',\n",
    "                                                                batch_size=batch_size,image_size=(IMG_SIZE,IMG_SIZE), #reshapeauto\n",
    "                                                                shuffle=True,seed=123,validation_split=0.4,subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1675fe53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['AF', 'NSR', 'PAC', 'PVC']\n"
     ]
    }
   ],
   "source": [
    "class_names = ds_train.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "20ab1eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of validation batches: 10\n",
      "Number of test batches: 10\n",
      "CPU times: total: 0 ns\n",
      "Wall time: 23 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "val_batches = tf.data.experimental.cardinality(ds_validate)\n",
    "test_dataset = ds_validate.take(300)\n",
    "validation_dataset = ds_validate.take(300)\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))\n",
    "\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset = ds_train.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = ds_validate.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db1b270",
   "metadata": {},
   "source": [
    "tf.data.experimental.cardinality():\n",
    "This function determines the cardinality of a dataset, i.e., the number of elements in the dataset. It helps us analyze the size and structure of our datasets.\n",
    "\n",
    "Dataset Preparation Steps:\n",
    "\n",
    "val_batches = tf.data.experimental.cardinality(ds_validate): We calculate the cardinality of the validation dataset ds_validate. The variable val_batches holds the number of batches in the validation dataset.\n",
    "\n",
    "test_dataset = ds_validate.take(300): We create a new dataset test_dataset by taking the first 300 elements from ds_validate. This dataset will be used for testing the trained model.\n",
    "\n",
    "validation_dataset = ds_validate.take(300): We create another dataset validation_dataset by also taking the first 300 elements from ds_validate. This dataset will be used for validation during model training.\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE: The AUTOTUNE value is used as a buffer size for prefetching data, allowing TensorFlow to optimize the data loading process automatically.\n",
    "\n",
    "train_dataset = ds_train.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE): We prepare the training dataset ds_train by caching it in memory, shuffling it with a buffer of 100 elements, and prefetching it using the AUTOTUNE buffer size.\n",
    "\n",
    "val_dataset = ds_validate.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE): Similarly, we prepare the validation dataset ds_validate by caching it in memory, shuffling it with a buffer of 100 elements, and prefetching it using the AUTOTUNE buffer size.\n",
    "\n",
    "The Significance of Dataset Preparation:\n",
    "\n",
    "By determining the cardinality of the validation dataset and creating subsets for validation and testing, we ensure that these datasets are of the appropriate size for model evaluation without overwhelming the memory.\n",
    "\n",
    "Caching and prefetching the datasets allow us to optimize data loading and minimize the time spent on data I/O during model training, significantly speeding up the overall training process.\n",
    "\n",
    "As we optimize the dataset preparation and profiling execution time, our data-driven journey continues to accelerate, unlocking the full potential of Python, TensorFlow, and GPU acceleration. Witness the remarkable progress as we delve deeper into the world of deep learning and ECG record analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "922a5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.RandomZoom(.5,.5),])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2044d16",
   "metadata": {},
   "source": [
    "#### Data Augmentation for Enhanced Deep Learning\n",
    "In our ongoing quest for improved model performance and generalization, we introduce a powerful technique called data augmentation. By utilizing data augmentation, we can increase the diversity of our training dataset and enhance the robustness of our deep learning model.\n",
    "\n",
    "##### Data Augmentation with TensorFlow and Keras:\n",
    "TensorFlow and Keras offer a wide array of data augmentation techniques to enrich the training dataset. Data augmentation involves applying various transformations to the images, such as rotation, translation, zooming, flipping, and more. These transformations introduce slight variations to the original images, creating new training samples that capture different aspects of the data distribution.\n",
    "\n",
    "tf.keras.layers.experimental.preprocessing.RandomZoom:\n",
    "The RandomZoom layer from TensorFlow's experimental preprocessing module allows us to apply random zooming to the images during training. The RandomZoom layer takes two arguments:\n",
    "\n",
    ".5: The zoom factor range, where 0.5 represents a zooming range of 50%. This means that the images can be zoomed in or out by up to 50%.\n",
    "\n",
    ".5: The height factor range, similar to the width factor range. In this case, we also set it to 0.5, representing a height zooming range of 50%.\n",
    "\n",
    "The Power of Data Augmentation:\n",
    "Data augmentation is an essential technique for mitigating overfitting and enhancing model generalization. By introducing variations to the training dataset through data augmentation, the model learns to be more robust to different patterns and image distortions that it may encounter during real-world scenarios.\n",
    "\n",
    "By employing data augmentation alongside deep learning, we harness the full potential of our Python program and TensorFlow integration. Our model gains the ability to generalize better, improving its performance on unseen data and increasing its real-world applicability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b6617f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = tf.keras.applications.efficientnet.preprocess_input\n",
    "rescale = tf.keras.layers.Rescaling(1./223.5, offset=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5426b9c0",
   "metadata": {},
   "source": [
    "#### Preprocessing Input and Rescaling for EfficientNet\n",
    "In our ongoing effort to enhance the performance of our deep learning model, we introduce two crucial components: preprocess_input and Rescaling. These components play a critical role in preparing the input data for the EfficientNet model, ensuring that it operates effectively and efficiently.\n",
    "\n",
    "preprocess_input for EfficientNet:\n",
    "The preprocess_input function from tf.keras.applications.efficientnet is used to preprocess the input data before feeding it into the EfficientNet model. EfficientNet, like many pre-trained models, requires input data to be preprocessed in a specific manner to ensure optimal performance.\n",
    "\n",
    "Rescaling Layer:\n",
    "The Rescaling layer from TensorFlow's tf.keras.layers module is used to rescale the input data. In this case, the input data is rescaled using a scale factor of 1/223.5 and an offset of -1. This normalization ensures that the input data falls within a specific range, typically between 0 and 1, which is often beneficial for neural network models.\n",
    "\n",
    "The Significance of Preprocessing and Rescaling:\n",
    "\n",
    "Preprocessing the input data using the preprocess_input function ensures that the data is formatted in a manner compatible with the EfficientNet model's requirements. This step might involve resizing the images, converting color formats, and normalizing pixel values to a specific range.\n",
    "\n",
    "The Rescaling layer is crucial for normalizing the input data to a standardized range. Normalizing the data helps the model converge faster during training, as it reduces the impact of large variations in pixel values.\n",
    "\n",
    "EfficientNet:\n",
    "EfficientNet is a highly efficient and accurate deep learning model that has gained popularity due to its excellent performance on various tasks. By integrating EfficientNet into our project and preparing the input data properly, we ensure that our model operates at its full potential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "93471849",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the base model from the pre-trained model EFB0\n",
    "base_model = tf.keras.applications.EfficientNetB0(input_shape=(224,224,3),\n",
    "                                                  include_top=False,\n",
    "                                                  weights='imagenet',\n",
    "                                                  classifier_activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74965aa0",
   "metadata": {},
   "source": [
    "#### Creating the Base Model with EfficientNetB0\n",
    "As we venture into building our deep learning model, we lay a strong foundation by creating the base model using EfficientNetB0. EfficientNetB0 is a pre-trained deep learning model that has demonstrated excellent performance in various computer vision tasks, making it a promising candidate for our ECG record analysis.\n",
    "\n",
    "EfficientNetB0:\n",
    "EfficientNet is a family of pre-trained convolutional neural network models developed by Google. EfficientNetB0 is the smallest variant in the family, designed to strike a balance between efficiency and performance. Despite its compact size, EfficientNetB0 delivers impressive results across various image recognition tasks.\n",
    "\n",
    "input_shape=(224, 224, 3):\n",
    "We specify the input shape of the images that will be fed into the EfficientNetB0 model. The input shape consists of three components: width, height, and the number of channels. In this case, we set the input shape to (224, 224, 3), indicating that the images have a resolution of 224x224 pixels and three color channels (RGB).\n",
    "\n",
    "include_top=False:\n",
    "By setting include_top to False, we exclude the fully connected layers (top) of the EfficientNetB0 model. We do this because we intend to add our custom top layers that are tailored to our specific task (ECG record analysis).\n",
    "\n",
    "weights='imagenet':\n",
    "The weights parameter specifies the weight initialization of the model. By setting it to 'imagenet', we initialize the model with pre-trained weights on the ImageNet dataset. This initialization provides a head start in training, as the model has already learned meaningful representations from a large and diverse image dataset.\n",
    "\n",
    "classifier_activation='softmax':\n",
    "The classifier_activation parameter determines the activation function for the classification layer (output layer). In this case, we set it to 'softmax', which is suitable for multi-class classification tasks like our ECG record analysis, where we have multiple classes to predict.\n",
    "\n",
    "The Importance of EfficientNetB0 as a Base Model:\n",
    "By leveraging EfficientNetB0 as the base model, we can harness its powerful feature extraction capabilities. This significantly simplifies the process of building a deep learning model for ECG record analysis, as we can focus on customizing the top layers to suit our classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6526c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 7, 7, 1280)\n"
     ]
    }
   ],
   "source": [
    "image_batch, label_batch = next(iter(train_dataset))\n",
    "feature_batch = base_model(image_batch)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10811f79",
   "metadata": {},
   "source": [
    "#### Extracting Features using EfficientNetB0\n",
    "As we embark on our deep learning journey, we take a significant step forward by using EfficientNetB0 to extract features from the input image batch. These features serve as essential representations of the images and are critical for building a robust and accurate ECG classification model.\n",
    "\n",
    "next(iter(train_dataset)):\n",
    "The next(iter(train_dataset)) expression retrieves the next batch of images and labels from the train_dataset. We use the Python iter() function to create an iterator from the train_dataset, and next() fetches the next batch.\n",
    "\n",
    "base_model(image_batch):\n",
    "We pass the image_batch through the base_model, which is the EfficientNetB0 model that we created earlier. The model extracts features from the input images.\n",
    "\n",
    "print(feature_batch.shape):\n",
    "The print() statement outputs the shape of the feature_batch, allowing us to inspect the dimensions of the extracted features.\n",
    "\n",
    "Extracting Features with EfficientNetB0:\n",
    "EfficientNetB0 is a powerful deep learning model that excels in feature extraction. By passing the image_batch through EfficientNetB0, we obtain a feature_batch, where each element in the batch represents the extracted features of a corresponding image.\n",
    "\n",
    "The Significance of Feature Extraction:\n",
    "Feature extraction is a crucial step in deep learning, as it enables the model to identify and represent relevant patterns and structures in the data. EfficientNetB0's ability to extract high-level features from images allows our ECG record analysis model to capture meaningful information that is essential for accurate classification.\n",
    "\n",
    "Understanding the feature_batch Shape:\n",
    "The feature_batch.shape output provides us with information about the shape of the extracted features. The shape typically consists of four dimensions, representing the batch size, spatial dimensions, and number of channels of the features.\n",
    "\n",
    "For example, if the output is (32, 7, 7, 1280), it indicates that the feature_batch contains 32 images (batch size) and each image is represented by a feature map of size 7x7 with 1280 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f23309c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = False #Freeze the convolutional base"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51bd877f",
   "metadata": {},
   "source": [
    "#### Freezing the Convolutional Base\n",
    "\n",
    "In our quest for effective transfer learning and model optimization, we take a crucial step by freezing the convolutional base of EfficientNetB0. By doing so, we prevent the weights of the base model from being updated during training, allowing us to focus on training only the custom top layers for our specific classification task.\n",
    "\n",
    "Freezing the Convolutional Base:\n",
    "When we set base_model.trainable to False, we freeze the convolutional base of EfficientNetB0. Freezing means that the weights of the base model's layers will remain fixed, and they will not be updated during the training process. This applies to all layers in the base model, including the feature extraction layers.\n",
    "\n",
    "The Importance of Freezing the Convolutional Base:\n",
    "Freezing the convolutional base has several advantages:\n",
    "\n",
    "Transfer Learning: EfficientNetB0 is a pre-trained model that has already learned useful features from a vast dataset (ImageNet). By freezing the convolutional base, we preserve these valuable pre-trained representations, which can greatly benefit our ECG record analysis task.\n",
    "\n",
    "Reduced Training Time: The majority of the model's parameters lie in the convolutional base. By freezing these layers, we significantly reduce the number of trainable parameters, leading to faster training times and lower memory requirements.\n",
    "\n",
    "Preventing Overfitting: Freezing the convolutional base helps prevent overfitting, especially when working with limited training data. Overfitting occurs when a model memorizes the training data, leading to poor generalization on new, unseen data. By freezing the base, we ensure that the model focuses on learning task-specific patterns rather than fitting to the training examples.\n",
    "\n",
    "Custom Top Layers: With the convolutional base frozen, we can now add custom top layers (such as fully connected or dense layers) on top of the EfficientNetB0 base. These custom layers will be responsible for learning task-specific representations and making predictions for our ECG record analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e98b637",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"efficientnetb0\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " rescaling_1 (Rescaling)     (None, 224, 224, 3)          0         ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " normalization (Normalizati  (None, 224, 224, 3)          7         ['rescaling_1[0][0]']         \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " rescaling_2 (Rescaling)     (None, 224, 224, 3)          0         ['normalization[0][0]']       \n",
      "                                                                                                  \n",
      " stem_conv_pad (ZeroPadding  (None, 225, 225, 3)          0         ['rescaling_2[0][0]']         \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)          (None, 112, 112, 32)         864       ['stem_conv_pad[0][0]']       \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalizatio  (None, 112, 112, 32)         128       ['stem_conv[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stem_activation (Activatio  (None, 112, 112, 32)         0         ['stem_bn[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block1a_dwconv (DepthwiseC  (None, 112, 112, 32)         288       ['stem_activation[0][0]']     \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block1a_bn (BatchNormaliza  (None, 112, 112, 32)         128       ['block1a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block1a_activation (Activa  (None, 112, 112, 32)         0         ['block1a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block1a_se_squeeze (Global  (None, 32)                   0         ['block1a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block1a_se_reshape (Reshap  (None, 1, 1, 32)             0         ['block1a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block1a_se_reduce (Conv2D)  (None, 1, 1, 8)              264       ['block1a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block1a_se_expand (Conv2D)  (None, 1, 1, 32)             288       ['block1a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block1a_se_excite (Multipl  (None, 112, 112, 32)         0         ['block1a_activation[0][0]',  \n",
      " y)                                                                  'block1a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv  (None, 112, 112, 16)         512       ['block1a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchN  (None, 112, 112, 16)         64        ['block1a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2  (None, 112, 112, 96)         1536      ['block1a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNo  (None, 112, 112, 96)         384       ['block2a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2a_expand_activation   (None, 112, 112, 96)         0         ['block2a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block2a_dwconv_pad (ZeroPa  (None, 113, 113, 96)         0         ['block2a_expand_activation[0]\n",
      " dding2D)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " block2a_dwconv (DepthwiseC  (None, 56, 56, 96)           864       ['block2a_dwconv_pad[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block2a_bn (BatchNormaliza  (None, 56, 56, 96)           384       ['block2a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block2a_activation (Activa  (None, 56, 56, 96)           0         ['block2a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block2a_se_squeeze (Global  (None, 96)                   0         ['block2a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block2a_se_reshape (Reshap  (None, 1, 1, 96)             0         ['block2a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block2a_se_reduce (Conv2D)  (None, 1, 1, 4)              388       ['block2a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block2a_se_expand (Conv2D)  (None, 1, 1, 96)             480       ['block2a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block2a_se_excite (Multipl  (None, 56, 56, 96)           0         ['block2a_activation[0][0]',  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y)                                                                  'block2a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv  (None, 56, 56, 24)           2304      ['block2a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchN  (None, 56, 56, 24)           96        ['block2a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2  (None, 56, 56, 144)          3456      ['block2a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNo  (None, 56, 56, 144)          576       ['block2b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2b_expand_activation   (None, 56, 56, 144)          0         ['block2b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block2b_dwconv (DepthwiseC  (None, 56, 56, 144)          1296      ['block2b_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block2b_bn (BatchNormaliza  (None, 56, 56, 144)          576       ['block2b_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block2b_activation (Activa  (None, 56, 56, 144)          0         ['block2b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block2b_se_squeeze (Global  (None, 144)                  0         ['block2b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block2b_se_reshape (Reshap  (None, 1, 1, 144)            0         ['block2b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block2b_se_reduce (Conv2D)  (None, 1, 1, 6)              870       ['block2b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block2b_se_expand (Conv2D)  (None, 1, 1, 144)            1008      ['block2b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block2b_se_excite (Multipl  (None, 56, 56, 144)          0         ['block2b_activation[0][0]',  \n",
      " y)                                                                  'block2b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv  (None, 56, 56, 24)           3456      ['block2b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchN  (None, 56, 56, 24)           96        ['block2b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)      (None, 56, 56, 24)           0         ['block2b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block2b_add (Add)           (None, 56, 56, 24)           0         ['block2b_drop[0][0]',        \n",
      "                                                                     'block2a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2  (None, 56, 56, 144)          3456      ['block2b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNo  (None, 56, 56, 144)          576       ['block3a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3a_expand_activation   (None, 56, 56, 144)          0         ['block3a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block3a_dwconv_pad (ZeroPa  (None, 59, 59, 144)          0         ['block3a_expand_activation[0]\n",
      " dding2D)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " block3a_dwconv (DepthwiseC  (None, 28, 28, 144)          3600      ['block3a_dwconv_pad[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block3a_bn (BatchNormaliza  (None, 28, 28, 144)          576       ['block3a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block3a_activation (Activa  (None, 28, 28, 144)          0         ['block3a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block3a_se_squeeze (Global  (None, 144)                  0         ['block3a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block3a_se_reshape (Reshap  (None, 1, 1, 144)            0         ['block3a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_se_reduce (Conv2D)  (None, 1, 1, 6)              870       ['block3a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block3a_se_expand (Conv2D)  (None, 1, 1, 144)            1008      ['block3a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block3a_se_excite (Multipl  (None, 28, 28, 144)          0         ['block3a_activation[0][0]',  \n",
      " y)                                                                  'block3a_se_expand[0][0]']   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " block3a_project_conv (Conv  (None, 28, 28, 40)           5760      ['block3a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchN  (None, 28, 28, 40)           160       ['block3a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2  (None, 28, 28, 240)          9600      ['block3a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNo  (None, 28, 28, 240)          960       ['block3b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3b_expand_activation   (None, 28, 28, 240)          0         ['block3b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block3b_dwconv (DepthwiseC  (None, 28, 28, 240)          6000      ['block3b_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block3b_bn (BatchNormaliza  (None, 28, 28, 240)          960       ['block3b_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block3b_activation (Activa  (None, 28, 28, 240)          0         ['block3b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block3b_se_squeeze (Global  (None, 240)                  0         ['block3b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block3b_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block3b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block3b_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block3b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block3b_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block3b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block3b_se_excite (Multipl  (None, 28, 28, 240)          0         ['block3b_activation[0][0]',  \n",
      " y)                                                                  'block3b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv  (None, 28, 28, 40)           9600      ['block3b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchN  (None, 28, 28, 40)           160       ['block3b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)      (None, 28, 28, 40)           0         ['block3b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block3b_add (Add)           (None, 28, 28, 40)           0         ['block3b_drop[0][0]',        \n",
      "                                                                     'block3a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2  (None, 28, 28, 240)          9600      ['block3b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNo  (None, 28, 28, 240)          960       ['block4a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4a_expand_activation   (None, 28, 28, 240)          0         ['block4a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4a_dwconv_pad (ZeroPa  (None, 29, 29, 240)          0         ['block4a_expand_activation[0]\n",
      " dding2D)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " block4a_dwconv (DepthwiseC  (None, 14, 14, 240)          2160      ['block4a_dwconv_pad[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormaliza  (None, 14, 14, 240)          960       ['block4a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4a_activation (Activa  (None, 14, 14, 240)          0         ['block4a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (Global  (None, 240)                  0         ['block4a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshap  (None, 1, 1, 240)            0         ['block4a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)  (None, 1, 1, 10)             2410      ['block4a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)  (None, 1, 1, 240)            2640      ['block4a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multipl  (None, 14, 14, 240)          0         ['block4a_activation[0][0]',  \n",
      " y)                                                                  'block4a_se_expand[0][0]']   \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block4a_project_conv (Conv  (None, 14, 14, 80)           19200     ['block4a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchN  (None, 14, 14, 80)           320       ['block4a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2  (None, 14, 14, 480)          38400     ['block4a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNo  (None, 14, 14, 480)          1920      ['block4b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4b_expand_activation   (None, 14, 14, 480)          0         ['block4b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4b_dwconv (DepthwiseC  (None, 14, 14, 480)          4320      ['block4b_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormaliza  (None, 14, 14, 480)          1920      ['block4b_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4b_activation (Activa  (None, 14, 14, 480)          0         ['block4b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (Global  (None, 480)                  0         ['block4b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block4b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block4b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block4b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multipl  (None, 14, 14, 480)          0         ['block4b_activation[0][0]',  \n",
      " y)                                                                  'block4b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv  (None, 14, 14, 80)           38400     ['block4b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchN  (None, 14, 14, 80)           320       ['block4b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)      (None, 14, 14, 80)           0         ['block4b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4b_add (Add)           (None, 14, 14, 80)           0         ['block4b_drop[0][0]',        \n",
      "                                                                     'block4a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2  (None, 14, 14, 480)          38400     ['block4b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNo  (None, 14, 14, 480)          1920      ['block4c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4c_expand_activation   (None, 14, 14, 480)          0         ['block4c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4c_dwconv (DepthwiseC  (None, 14, 14, 480)          4320      ['block4c_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormaliza  (None, 14, 14, 480)          1920      ['block4c_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4c_activation (Activa  (None, 14, 14, 480)          0         ['block4c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (Global  (None, 480)                  0         ['block4c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block4c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block4c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block4c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multipl  (None, 14, 14, 480)          0         ['block4c_activation[0][0]',  \n",
      " y)                                                                  'block4c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv  (None, 14, 14, 80)           38400     ['block4c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchN  (None, 14, 14, 80)           320       ['block4c_project_conv[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)      (None, 14, 14, 80)           0         ['block4c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_add (Add)           (None, 14, 14, 80)           0         ['block4c_drop[0][0]',        \n",
      "                                                                     'block4b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2  (None, 14, 14, 480)          38400     ['block4c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNo  (None, 14, 14, 480)          1920      ['block5a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5a_expand_activation   (None, 14, 14, 480)          0         ['block5a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5a_dwconv (DepthwiseC  (None, 14, 14, 480)          12000     ['block5a_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormaliza  (None, 14, 14, 480)          1920      ['block5a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5a_activation (Activa  (None, 14, 14, 480)          0         ['block5a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (Global  (None, 480)                  0         ['block5a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshap  (None, 1, 1, 480)            0         ['block5a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)  (None, 1, 1, 20)             9620      ['block5a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)  (None, 1, 1, 480)            10080     ['block5a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multipl  (None, 14, 14, 480)          0         ['block5a_activation[0][0]',  \n",
      " y)                                                                  'block5a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv  (None, 14, 14, 112)          53760     ['block5a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchN  (None, 14, 14, 112)          448       ['block5a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2  (None, 14, 14, 672)          75264     ['block5a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNo  (None, 14, 14, 672)          2688      ['block5b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5b_expand_activation   (None, 14, 14, 672)          0         ['block5b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5b_dwconv (DepthwiseC  (None, 14, 14, 672)          16800     ['block5b_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormaliza  (None, 14, 14, 672)          2688      ['block5b_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5b_activation (Activa  (None, 14, 14, 672)          0         ['block5b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (Global  (None, 672)                  0         ['block5b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multipl  (None, 14, 14, 672)          0         ['block5b_activation[0][0]',  \n",
      " y)                                                                  'block5b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv  (None, 14, 14, 112)          75264     ['block5b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchN  (None, 14, 14, 112)          448       ['block5b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)      (None, 14, 14, 112)          0         ['block5b_project_bn[0][0]']  \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block5b_add (Add)           (None, 14, 14, 112)          0         ['block5b_drop[0][0]',        \n",
      "                                                                     'block5a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2  (None, 14, 14, 672)          75264     ['block5b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNo  (None, 14, 14, 672)          2688      ['block5c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5c_expand_activation   (None, 14, 14, 672)          0         ['block5c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5c_dwconv (DepthwiseC  (None, 14, 14, 672)          16800     ['block5c_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormaliza  (None, 14, 14, 672)          2688      ['block5c_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5c_activation (Activa  (None, 14, 14, 672)          0         ['block5c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (Global  (None, 672)                  0         ['block5c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multipl  (None, 14, 14, 672)          0         ['block5c_activation[0][0]',  \n",
      " y)                                                                  'block5c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv  (None, 14, 14, 112)          75264     ['block5c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchN  (None, 14, 14, 112)          448       ['block5c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)      (None, 14, 14, 112)          0         ['block5c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_add (Add)           (None, 14, 14, 112)          0         ['block5c_drop[0][0]',        \n",
      "                                                                     'block5b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2  (None, 14, 14, 672)          75264     ['block5c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNo  (None, 14, 14, 672)          2688      ['block6a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6a_expand_activation   (None, 14, 14, 672)          0         ['block6a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6a_dwconv_pad (ZeroPa  (None, 17, 17, 672)          0         ['block6a_expand_activation[0]\n",
      " dding2D)                                                           [0]']                         \n",
      "                                                                                                  \n",
      " block6a_dwconv (DepthwiseC  (None, 7, 7, 672)            16800     ['block6a_dwconv_pad[0][0]']  \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormaliza  (None, 7, 7, 672)            2688      ['block6a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6a_activation (Activa  (None, 7, 7, 672)            0         ['block6a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (Global  (None, 672)                  0         ['block6a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block6a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block6a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block6a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multipl  (None, 7, 7, 672)            0         ['block6a_activation[0][0]',  \n",
      " y)                                                                  'block6a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv  (None, 7, 7, 192)            129024    ['block6a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchN  (None, 7, 7, 192)            768       ['block6a_project_conv[0][0]']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2  (None, 7, 7, 1152)           221184    ['block6a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNo  (None, 7, 7, 1152)           4608      ['block6b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6b_expand_activation   (None, 7, 7, 1152)           0         ['block6b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6b_dwconv (DepthwiseC  (None, 7, 7, 1152)           28800     ['block6b_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormaliza  (None, 7, 7, 1152)           4608      ['block6b_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6b_activation (Activa  (None, 7, 7, 1152)           0         ['block6b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (Global  (None, 1152)                 0         ['block6b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multipl  (None, 7, 7, 1152)           0         ['block6b_activation[0][0]',  \n",
      " y)                                                                  'block6b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv  (None, 7, 7, 192)            221184    ['block6b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchN  (None, 7, 7, 192)            768       ['block6b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)      (None, 7, 7, 192)            0         ['block6b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6b_add (Add)           (None, 7, 7, 192)            0         ['block6b_drop[0][0]',        \n",
      "                                                                     'block6a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2  (None, 7, 7, 1152)           221184    ['block6b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNo  (None, 7, 7, 1152)           4608      ['block6c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6c_expand_activation   (None, 7, 7, 1152)           0         ['block6c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6c_dwconv (DepthwiseC  (None, 7, 7, 1152)           28800     ['block6c_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormaliza  (None, 7, 7, 1152)           4608      ['block6c_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6c_activation (Activa  (None, 7, 7, 1152)           0         ['block6c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (Global  (None, 1152)                 0         ['block6c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multipl  (None, 7, 7, 1152)           0         ['block6c_activation[0][0]',  \n",
      " y)                                                                  'block6c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv  (None, 7, 7, 192)            221184    ['block6c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchN  (None, 7, 7, 192)            768       ['block6c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)      (None, 7, 7, 192)            0         ['block6c_project_bn[0][0]']  \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " block6c_add (Add)           (None, 7, 7, 192)            0         ['block6c_drop[0][0]',        \n",
      "                                                                     'block6b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2  (None, 7, 7, 1152)           221184    ['block6c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNo  (None, 7, 7, 1152)           4608      ['block6d_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6d_expand_activation   (None, 7, 7, 1152)           0         ['block6d_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6d_dwconv (DepthwiseC  (None, 7, 7, 1152)           28800     ['block6d_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormaliza  (None, 7, 7, 1152)           4608      ['block6d_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6d_activation (Activa  (None, 7, 7, 1152)           0         ['block6d_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (Global  (None, 1152)                 0         ['block6d_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6d_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6d_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6d_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multipl  (None, 7, 7, 1152)           0         ['block6d_activation[0][0]',  \n",
      " y)                                                                  'block6d_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv  (None, 7, 7, 192)            221184    ['block6d_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchN  (None, 7, 7, 192)            768       ['block6d_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)      (None, 7, 7, 192)            0         ['block6d_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6d_add (Add)           (None, 7, 7, 192)            0         ['block6d_drop[0][0]',        \n",
      "                                                                     'block6c_add[0][0]']         \n",
      "                                                                                                  \n",
      " block7a_expand_conv (Conv2  (None, 7, 7, 1152)           221184    ['block6d_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block7a_expand_bn (BatchNo  (None, 7, 7, 1152)           4608      ['block7a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block7a_expand_activation   (None, 7, 7, 1152)           0         ['block7a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block7a_dwconv (DepthwiseC  (None, 7, 7, 1152)           10368     ['block7a_expand_activation[0]\n",
      " onv2D)                                                             [0]']                         \n",
      "                                                                                                  \n",
      " block7a_bn (BatchNormaliza  (None, 7, 7, 1152)           4608      ['block7a_dwconv[0][0]']      \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block7a_activation (Activa  (None, 7, 7, 1152)           0         ['block7a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block7a_se_squeeze (Global  (None, 1152)                 0         ['block7a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block7a_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block7a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block7a_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block7a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block7a_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block7a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block7a_se_excite (Multipl  (None, 7, 7, 1152)           0         ['block7a_activation[0][0]',  \n",
      " y)                                                                  'block7a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block7a_project_conv (Conv  (None, 7, 7, 320)            368640    ['block7a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block7a_project_bn (BatchN  (None, 7, 7, 320)            1280      ['block7a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)           (None, 7, 7, 1280)           409600    ['block7a_project_bn[0][0]']  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " top_bn (BatchNormalization  (None, 7, 7, 1280)           5120      ['top_conv[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " top_activation (Activation  (None, 7, 7, 1280)           0         ['top_bn[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4049571 (15.45 MB)\n",
      "Trainable params: 0 (0.00 Byte)\n",
      "Non-trainable params: 4049571 (15.45 MB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "238"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's take a look at the base model architecture\n",
    "base_model.summary()\n",
    "len(base_model.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f6f69126",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1280)\n"
     ]
    }
   ],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "feature_batch_average = global_average_layer(feature_batch)\n",
    "print(feature_batch_average.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6819fa8d",
   "metadata": {},
   "source": [
    "#### Global Average Pooling for Feature Aggregation\n",
    "In our endeavor to process the extracted features effectively, we introduce Global Average Pooling 2D (GAP), a crucial operation for feature aggregation. By employing GAP, we transform the spatial dimensions of the feature maps into a single value per channel, condensing the information into a compact representation.\n",
    "\n",
    "tf.keras.layers.GlobalAveragePooling2D():\n",
    "The GlobalAveragePooling2D layer is employed to perform Global Average Pooling on the input feature maps. This operation is specifically designed for 2D data (images) and is often used after the convolutional layers to aggregate spatial information.\n",
    "\n",
    "Feature Aggregation with Global Average Pooling:\n",
    "When we apply GlobalAveragePooling2D to the feature_batch, it reduces the spatial dimensions (width and height) of each feature map to a single value per channel. This aggregation is performed independently for each channel in the feature maps.\n",
    "\n",
    "The Significance of Feature Aggregation:\n",
    "Feature aggregation with Global Average Pooling is beneficial for several reasons:\n",
    "\n",
    "Dimension Reduction: Global Average Pooling reduces the spatial dimensions of the feature maps, effectively compressing the information into a more concise representation. This helps in reducing the computational complexity and memory requirements in subsequent layers.\n",
    "\n",
    "Translation Invariance: Global Average Pooling makes the model more translation-invariant. By averaging features across the spatial dimensions, the model becomes less sensitive to the exact location of the features within an image. This can lead to improved generalization and robustness.\n",
    "\n",
    "Global Context: Aggregating features globally enables the model to consider the entire input image when making predictions. This global context can be especially useful in tasks where important features may be spread across the entire image.\n",
    "\n",
    "Understanding the feature_batch_average Shape:\n",
    "The feature_batch_average.shape output represents the shape of the feature maps after Global Average Pooling is applied. Since GAP reduces the spatial dimensions to a single value per channel, the resulting shape will typically be (batch_size, num_channels).\n",
    "\n",
    "For example, if the output is (32, 1280), it indicates that the feature_batch_average has 32 elements (images in the batch), and each image's features are represented by a vector of length 1280 (one value per channel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71c56c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 4\n",
    "inputs = tf.keras.Input(shape=(224,224, 3))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(inputs)\n",
    "x = base_model(x, training=False)\n",
    "      # call it on the given tensor\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Dropout(0.4)(x)\n",
    "initializer = tf.keras.initializers.GlorotUniform(seed=123)\n",
    "activation = None  #tf.keras.activations.softmax\n",
    "outputs =outputs = keras.layers.Dense(number_of_classes,\n",
    "                                      activation=activation,name=\"predictions\")(x) \n",
    "efficientNet = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3ff16b",
   "metadata": {},
   "source": [
    "By building on the foundation of EfficientNetB0, data augmentation, and Global Average Pooling, we create a custom model tailored to our specific ECG classification task.\n",
    "\n",
    "The Model Building Process:\n",
    "The model is constructed in a step-by-step manner:\n",
    "\n",
    "Input Layer: We define the input layer with the desired input shape (224, 224, 3) to accommodate the images in our ECG record dataset.\n",
    "\n",
    "Data Augmentation: The input images undergo data augmentation using the previously defined data_augmentation layer. Data augmentation introduces random transformations to the images, increasing the diversity of the training dataset and improving the model's ability to generalize.\n",
    "\n",
    "Preprocess Input: The images are preprocessed using the preprocess_input function, ensuring they are formatted appropriately for EfficientNetB0.\n",
    "\n",
    "Feature Extraction: The preprocessed images are passed through the EfficientNetB0 base model, and features are extracted using the previously defined base_model.\n",
    "\n",
    "Global Average Pooling: Global Average Pooling is applied to the extracted features, aggregating spatial information into a compact representation.\n",
    "\n",
    "Batch Normalization: Batch Normalization is added to improve the convergence speed and stability of the training process.\n",
    "\n",
    "Dropout: Dropout regularization is implemented with a dropout rate of 0.4 to prevent overfitting during training.\n",
    "\n",
    "Dense Layer (Classification Layer): A dense layer (fully connected layer) with number_of_classes neurons is added to perform the final classification. Since this is a multi-class classification task, we omit specifying an activation function at this stage.\n",
    "\n",
    "The EfficientNet-Based ECG Classification Model: We combine the input and output layers to create the final model named efficientNet.\n",
    "\n",
    "The Significance of the Model Architecture:\n",
    "By customizing the EfficientNetB0 base model and adding additional layers, we create a cardiac arrhythmias classification model that is specifically tailored to our classification task. The model is designed to extract relevant features from ECG images, aggregate them through Global Average Pooling, and make accurate predictions for the multiple classes in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0b98542",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_learning_rate = 0.01\n",
    "efficientNet.compile(optimizer=keras.optimizers.Adam(),\n",
    "              loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), # default from_logits=False\n",
    "              metrics=[keras.metrics.SparseCategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e94fd2e",
   "metadata": {},
   "source": [
    "#### Compiling and Configuring the EfficientNet Model\n",
    "With the ECG record analysis model architecture in place, we move forward to compile and configure the model. This step involves specifying the optimizer, loss function, and evaluation metrics, enabling us to begin the training process.\n",
    "\n",
    "Model Compilation and Configuration:\n",
    "The compilation step involves defining various components essential for model training:\n",
    "\n",
    "Optimizer: We use the Adam optimizer to train the model. Adam is an efficient optimization algorithm that adapts the learning rate dynamically during training, making it well-suited for deep learning tasks.\n",
    "\n",
    "Learning Rate: We specify the initial learning rate for the Adam optimizer. The base_learning_rate is set to 0.01, which determines how much the model's weights are updated during each training step. The learning rate can be tuned to control the rate of convergence and model performance.\n",
    "\n",
    "Loss Function: For multi-class classification tasks with integer labels (like our ECG record analysis), we use SparseCategoricalCrossentropy as the loss function. This function is appropriate when the target labels are provided as integers, and the model's output contains logits (unnormalized log probabilities). Setting from_logits=True indicates that the model outputs logits, which is usually the case for multi-class classification tasks.\n",
    "\n",
    "Metrics: We use SparseCategoricalAccuracy as the evaluation metric. This metric calculates the accuracy of the model predictions when the target labels are provided as integers (sparse).\n",
    "\n",
    "The Significance of Model Compilation:\n",
    "Compiling the model is a crucial step in preparing it for training. By specifying the optimizer, loss function, and metrics, we configure the model to optimize its parameters, compute the loss during training, and evaluate its performance on the validation dataset.\n",
    "\n",
    "Training Begins:\n",
    "Once the model is compiled and configured, we are all set to begin the training process. During training, the model will iteratively update its weights using the specified optimizer, minimizing the loss function, and improving its performance on the ECG record analysis task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe06ec1",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "15/15 [==============================] - 87s 5s/step - loss: 1.2128 - sparse_categorical_accuracy: 0.5547 - val_loss: 0.9373 - val_sparse_categorical_accuracy: 0.6777\n",
      "Epoch 2/100\n",
      "15/15 [==============================] - 74s 5s/step - loss: 0.5291 - sparse_categorical_accuracy: 0.8156 - val_loss: 0.8074 - val_sparse_categorical_accuracy: 0.7448\n",
      "Epoch 3/100\n",
      "15/15 [==============================] - 73s 5s/step - loss: 0.3981 - sparse_categorical_accuracy: 0.8541 - val_loss: 0.7310 - val_sparse_categorical_accuracy: 0.7851\n",
      "Epoch 4/100\n",
      "15/15 [==============================] - 79s 5s/step - loss: 0.3392 - sparse_categorical_accuracy: 0.8844 - val_loss: 0.6721 - val_sparse_categorical_accuracy: 0.8233\n",
      "Epoch 5/100\n",
      "15/15 [==============================] - ETA: 0s - loss: 0.2787 - sparse_categorical_accuracy: 0.9071"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "first_hist=efficientNet.fit(train_dataset, validation_data=val_dataset, batch_size=100, epochs=100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db73911b",
   "metadata": {},
   "source": [
    "#### Training the EfficientNet Model\n",
    "\n",
    "With the model compiled and configured, we proceed to the training phase, where the EfficientNet-based ECG record analysis model learns from the training dataset. Training involves iteratively updating the model's weights to minimize the loss function and improve its ability to make accurate predictions.\n",
    "\n",
    "Training the Model:\n",
    "\n",
    "efficientNet.fit: The fit method is called on the efficientNet model to initiate the training process. This method takes the following arguments:\n",
    "\n",
    "train_dataset: The training dataset, which contains the ECG record images and their corresponding labels. The model will learn from this dataset to make accurate predictions.\n",
    "\n",
    "validation_data: The validation dataset, which is used to evaluate the model's performance during training. It contains images and labels separate from the training dataset and helps us monitor the model's ability to generalize to unseen data.\n",
    "\n",
    "batch_size: The number of samples in each batch during training. In this case, we use a batch size of 100, meaning the model will update its weights after processing each batch of 100 images.\n",
    "\n",
    "epochs: The number of times the model will iterate over the entire training dataset during training. In this case, we set epochs=100, which means the model will go through the entire training dataset 100 times.\n",
    "\n",
    "Monitoring Training Time:\n",
    "The %%time magic command is used to measure the training time. This command calculates and displays the time taken to complete the training process.\n",
    "\n",
    "The Training Process:\n",
    "During training, the model processes batches of training data, computes the loss function, and updates its weights using the Adam optimizer. The model's performance on the validation dataset is evaluated after each epoch, allowing us to monitor its progress and identify possible overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8024071",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientNet.save('ecg_trial_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48a32fa",
   "metadata": {},
   "source": [
    "#### Saving the Trained EfficientNet Model\n",
    "\n",
    "Congratulations on completing the training phase of the EfficientNet-based ECG record analysis model! The progress you've made so far is truly commendable. Now, let's take a moment to preserve this well-trained model for future use and further exploration.\n",
    "\n",
    "Saving the Model:\n",
    "The save method is called on the efficientNet model to save it to a file. We provide the filename as \"ecg_trial_model.h5\". The \".h5\" extension is a common choice for saving models using the Hierarchical Data Format (HDF5), which is a binary data format commonly used in machine learning.\n",
    "\n",
    "Model Preservation:\n",
    "By saving the model to a file, we ensure that the trained weights, architecture, and configuration of the model are stored for future use. This allows us to easily reload the model at a later time without needing to retrain it, which can be especially useful for tasks such as evaluation, deployment, and transfer learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77808de",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.saved_model.save(efficientNet, \"ecgmodel_saved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dd1f50e",
   "metadata": {},
   "source": [
    "#### Saving the Trained EfficientNet Model as a SavedModel\n",
    "In addition to saving the model in the HDF5 format, TensorFlow provides another convenient way to save models, known as the SavedModel format. This format allows for a more comprehensive preservation of the model, including its architecture, weights, and computation graph, making it easy to deploy the model across different platforms and environments.\n",
    "\n",
    "Saving as a SavedModel:\n",
    "The tf.saved_model.save function is used to save the model as a SavedModel. We pass the efficientNet model object as the first argument and specify the directory where the SavedModel will be saved. In this case, we provide the directory name as \"ecgmodel_saved\".\n",
    "\n",
    "Advantages of the SavedModel Format:\n",
    "The SavedModel format offers several benefits:\n",
    "\n",
    "Comprehensive Preservation: The SavedModel format preserves not only the model's architecture and weights but also the computation graph, custom layers, and optimizer states. This makes it easier to reload and deploy the model without losing any essential information.\n",
    "\n",
    "Platform-Agnostic: The SavedModel format is platform-agnostic, meaning it can be used across different platforms, languages, and TensorFlow versions. This portability is particularly useful when deploying models to production environments or sharing them with others.\n",
    "\n",
    "Serving with TensorFlow Serving: The SavedModel format is the standard for deploying models with TensorFlow Serving, a dedicated system for deploying machine learning models in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d4829c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(efficientNet)\n",
    "efficient_tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open('model.tflite', 'wb') as f:\n",
    "  f.write(efficient_tflite_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d26ebe",
   "metadata": {},
   "source": [
    "#### Converting the Trained EfficientNet Model to TensorFlow Lite\n",
    "\n",
    "With the trained EfficientNet model at our disposal, we can take a significant step towards optimizing and deploying the model on resource-constrained devices. TensorFlow Lite (TFLite) is a framework designed for running machine learning models efficiently on edge devices, mobile devices, and microcontrollers.\n",
    "\n",
    "Converting to TensorFlow Lite:\n",
    "To convert the trained EfficientNet model to TensorFlow Lite, we use the tf.lite.TFLiteConverter.from_keras_model function. This converter takes the efficientNet model as input and performs the necessary transformations to optimize it for deployment on edge devices.\n",
    "\n",
    "Saving the TensorFlow Lite Model:\n",
    "After converting the model, we save it to a file with the extension \".tflite\". The model is written to the file in binary format using the write method.\n",
    "\n",
    "##### The Benefits of TensorFlow Lite:\n",
    "TensorFlow Lite offers several advantages:\n",
    "\n",
    "Efficiency: TensorFlow Lite is designed for running models efficiently on devices with limited computational resources, making it well-suited for edge devices and mobile applications.\n",
    "\n",
    "Accelerated Inference: TFLite supports hardware acceleration (e.g., through the use of Tensor Processing Units, GPU acceleration, or Neural Processing Units), leading to faster inference times on compatible devices.\n",
    "\n",
    "Reduced Model Size: Models converted to TensorFlow Lite are often smaller in size compared to their original counterparts, making them easier to deploy and distribute.\n",
    "\n",
    "On-Device Inference: TensorFlow Lite enables on-device inference, meaning the model can make predictions directly on the device without relying on a cloud or server."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1060980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = first_hist.history['sparse_categorical_accuracy']\n",
    "val_acc = first_hist.history['val_sparse_categorical_accuracy']\n",
    "\n",
    "loss = first_hist.history['loss']\n",
    "val_loss = first_hist.history['val_loss']\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.style.use('_classic_test_patch')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.style.use('_classic_test_patch')\n",
    "plt.grid(True)\n",
    "plt.plot(acc, label='Training Accuracy')\n",
    "plt.plot(val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([min(plt.ylim()),1])\n",
    "plt.title('Training and Validation Accuracy with EfficientNet')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.style.use('_classic_test_patch')\n",
    "plt.grid(True)\n",
    "plt.plot(loss, label='Training Loss')\n",
    "plt.plot(val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.ylabel('Cross Entropy')\n",
    "plt.ylim([0,1.0])\n",
    "plt.title('Training and Validation Loss with EfficientNet')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c20007",
   "metadata": {},
   "source": [
    "#### Visualization of Training and Validation Metrics\n",
    "Visualizing the training and validation metrics helps us gain insights into the model's performance during the training process. By plotting the accuracy and loss values over the epochs, we can observe the model's learning progress and identify possible overfitting or underfitting.\n",
    "\n",
    "Plotting Training and Validation Metrics:\n",
    "In this code snippet, we use matplotlib to create two subplots, each displaying the training and validation metrics for accuracy and loss.\n",
    "\n",
    "Training and Validation Accuracy Plot: The first subplot displays the training and validation accuracy over the epochs. The training accuracy is plotted as a line graph with the label \"Training Accuracy,\" while the validation accuracy is represented by another line graph with the label \"Validation Accuracy.\"\n",
    "\n",
    "Training and Validation Loss Plot: The second subplot shows the training and validation loss over the epochs. The training loss is depicted as a line graph with the label \"Training Loss,\" and the validation loss is displayed as another line graph with the label \"Validation Loss.\"\n",
    "\n",
    "##### Interpreting the Plots:\n",
    "\n",
    "For the accuracy plot, higher values indicate better performance. Ideally, both training and validation accuracy should increase with each epoch, but if validation accuracy starts to plateau or decrease while training accuracy continues to increase, it may be a sign of overfitting.\n",
    "\n",
    "For the loss plot, lower values indicate better performance. Both training and validation loss should decrease with each epoch. If validation loss starts to increase while training loss continues to decrease, it may indicate overfitting.\n",
    "\n",
    "By analyzing these plots, we can make informed decisions about model optimization and generalization, ensuring the trained model performs well on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a789a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "loss, accuracy= efficientNet.evaluate(test_dataset)\n",
    "print('Test accuracy :', accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c473469",
   "metadata": {},
   "source": [
    "#### Evaluating the Trained EfficientNet Model on the Test Dataset\n",
    "To gauge the model's performance on unseen data, we evaluate the trained EfficientNet model on the test dataset. By computing the loss and accuracy metrics on the test dataset, we can ascertain how well the model generalizes to real-world examples.\n",
    "\n",
    "Model Evaluation:\n",
    "In this code snippet, we use the evaluate method to assess the model's performance on the test dataset multiple times.\n",
    "\n",
    "Evaluating Test Accuracy:\n",
    "For each evaluation, the model's loss and accuracy on the test dataset are computed. The resulting accuracy indicates the proportion of correctly classified samples in the test dataset.\n",
    "\n",
    "Interpreting Test Accuracy:\n",
    "The test accuracy provides valuable insights into how well the model generalizes to unseen data. A high test accuracy indicates that the model is performing well on the test dataset and can make accurate predictions on real-world examples. On the other hand, a low test accuracy may suggest overfitting or limitations in generalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac3f192",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ds_validate=tf.keras.preprocessing.image_dataset_from_directory(\"D:\\\\ECG DB\\\\FourClasseswith 20percent mixed\",\n",
    "                                                                labels='inferred',label_mode=\"int\",\n",
    "                                                                class_names=['AF','NSR','PAC','PVC'],color_mode='rgb',\n",
    "                                                                batch_size=548,image_size=(IMG_SIZE,IMG_SIZE), #reshapeauto\n",
    "                                                                shuffle=True,seed=123,validation_split=0.4,subset=\"validation\")\n",
    "\n",
    "test_dataset = ds_validate.take(548)\n",
    "validation_dataset = ds_validate.skip(400)\n",
    "print('Number of validation batches: %d' % tf.data.experimental.cardinality(validation_dataset))\n",
    "print('Number of test batches: %d' % tf.data.experimental.cardinality(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddcfbeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=548\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = efficientNet.predict(image_batch)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0766c9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes=[]\n",
    "for i in range(548):\n",
    "    predicted_class=np.argmax(predictions[i])\n",
    "    predicted_classes.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f00b972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true=label_batch\n",
    "y_pred=np.array(predicted_classes)\n",
    "confusion_matrix(y_true, y_pred)\n",
    "\n",
    "data = {'y_Actual': y_true,\n",
    "        'y_Predicted': y_pred\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6bd578",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22672a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AF_SandS (conf_matrix):\n",
    "    TP= conf_matrix[0][0]\n",
    "    TN= (conf_matrix[1][1]+conf_matrix[2][2]+conf_matrix[3][3]+\n",
    "               conf_matrix[1][2]+conf_matrix[1][3]+conf_matrix[2][1]+conf_matrix[2][3]+conf_matrix[3][1]+conf_matrix[3][2])\n",
    "    FP= conf_matrix[0][1]+conf_matrix[0][2]+conf_matrix[0][3]\n",
    "    FN= conf_matrix[1][0]+conf_matrix[2][0]+conf_matrix[3][0]    \n",
    "    accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
    "    misclassification = 1- accuracy\n",
    "    sensitivity = (TP / float(TP + FN))\n",
    "    specificity = (TN / float(TN + FP))\n",
    "    \n",
    "    print('-'*50)\n",
    "    print('AF')\n",
    "    print(f'Accuracy: {(accuracy)}') \n",
    "    print(f'Mis-Classification: {round(misclassification,2)}') \n",
    "    print(f'Sensitivity: {(sensitivity)}') \n",
    "    print(f'Specificity: {(specificity)}') \n",
    "\n",
    "    \n",
    "def NSR_SandS (conf_matrix):\n",
    "    TP= conf_matrix[1][1]\n",
    "    TN= (conf_matrix[0][0]+conf_matrix[2][2]+conf_matrix[3][3]+\n",
    "               conf_matrix[0][2]+conf_matrix[0][3]+conf_matrix[2][0]+conf_matrix[2][3]+conf_matrix[3][0]+conf_matrix[3][2])\n",
    "    FP= conf_matrix[1][0]+conf_matrix[1][2]+conf_matrix[1][3]\n",
    "    FN= conf_matrix[0][1]+conf_matrix[2][1]+conf_matrix[3][1]    \n",
    "    #accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
    "    misclassification = 1- accuracy\n",
    "    sensitivity = (TP / float(TP + FN))\n",
    "    specificity = (TN / float(TN + FP))\n",
    "    \n",
    "    print('-'*50)\n",
    "    print('NSR')\n",
    "    print(f'Accuracy: {(accuracy)}') \n",
    "    print(f'Mis-Classification: {round(misclassification,2)}') \n",
    "    print(f'Sensitivity: {(sensitivity)}') \n",
    "    print(f'Specificity: {(specificity)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f681c68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PAC_SandS (conf_matrix):\n",
    "    TP= conf_matrix[2][2]\n",
    "    TN= (conf_matrix[0][0]+conf_matrix[1][1]+conf_matrix[3][3]+\n",
    "               conf_matrix[0][1]+conf_matrix[0][3]+conf_matrix[1][0]+conf_matrix[1][3]+conf_matrix[3][0]+conf_matrix[3][1])\n",
    "    FP= conf_matrix[2][0]+conf_matrix[2][1]+conf_matrix[2][3]\n",
    "    FN= conf_matrix[0][2]+conf_matrix[1][2]+conf_matrix[3][2]    \n",
    "    accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
    "    misclassification = 1- accuracy\n",
    "    sensitivity = (TP / float(TP + FN))\n",
    "    specificity = (TN / float(TN + FP))\n",
    "    \n",
    "    print('-'*50)\n",
    "    print('PAC')\n",
    "    print(f'Accuracy: {(accuracy)}') \n",
    "    print(f'Mis-Classification: {round(misclassification,2)}') \n",
    "    print(f'Sensitivity: {(sensitivity)}') \n",
    "    print(f'Specificity: {(specificity)}') \n",
    "    \n",
    "    \n",
    "def PVC_SandS (conf_matrix):\n",
    "    TP= conf_matrix[3][3]\n",
    "    TN= (conf_matrix[0][0]+conf_matrix[1][1]+conf_matrix[2][2]+\n",
    "               conf_matrix[0][1]+conf_matrix[0][2]+conf_matrix[1][0]+conf_matrix[1][2]+conf_matrix[2][0]+conf_matrix[2][1])\n",
    "    FP= conf_matrix[3][0]+conf_matrix[3][1]+conf_matrix[3][2]\n",
    "    FN= conf_matrix[0][3]+conf_matrix[1][3]+conf_matrix[2][3]    \n",
    "    accuracy = (float (TP+TN) / float(TP + TN + FP + FN))\n",
    "    misclassification = 1- accuracy\n",
    "    sensitivity = (TP / float(TP + FN))\n",
    "    specificity = (TN / float(TN + FP))\n",
    "    \n",
    "    print('-'*50)\n",
    "    print('PVC')\n",
    "    print(f'Accuracy: {(accuracy)}') \n",
    "    print(f'Mis-Classification: {round(misclassification,2)}') \n",
    "    print(f'Sensitivity: {(sensitivity)}') \n",
    "    print(f'Specificity: {(specificity)}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e592e96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "AF_SandS(confusion_matrix)\n",
    "NSR_SandS(confusion_matrix)\n",
    "PAC_SandS(confusion_matrix)\n",
    "PVC_SandS(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e561237",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_true=label_batch\n",
    "y_pred=np.array(predicted_classes)\n",
    "target_names = ['AF', 'NSR', 'PAC','PVC']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07afdcb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatched=np.where(np.array(predicted_classes)!=label_batch)[0]\n",
    "mismatched\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba0972e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.suptitle(\"REAL is\"+target_names[label_batch[mismatched[3]]])\n",
    "plt.title(\"Predicted as\"+target_names[predicted_classes[mismatched[3]]])\n",
    "plt.axis(\"off\")\n",
    "plt.imshow(image_batch[mismatched[3]].astype(\"uint8\"))\n",
    "#plt.savefig(str(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f97d8e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=keras.utils.image_dataset_from_directory(directory='D:\\\\ECG DB\\\\TTV twentypercent\\\\Test',\n",
    "                                                    labels='inferred',\n",
    "                                                    label_mode='int',\n",
    "                                                    class_names=['AF','NSR','PAC','PVC'],\n",
    "                                                    batch_size=561,shuffle=True,seed=123,\n",
    "                                                    image_size=(224, 224))\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = efficientNet.predict(image_batch)\n",
    "predictions.shape\n",
    "predicted_classes=[]\n",
    "for i in range(561):\n",
    "    predicted_class=np.argmax(predictions[i])\n",
    "    predicted_classes.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b77c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true=label_batch\n",
    "y_pred=np.array(predicted_classes)\n",
    "confusion_matrix(y_true, y_pred)\n",
    "\n",
    "data = {'y_Actual': y_true,\n",
    "        'y_Predicted': y_pred\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b7a35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset=keras.utils.image_dataset_from_directory(directory='D:\\\\ECG DB\\\\PAC 11to15',\n",
    "                                                    labels='inferred',\n",
    "                                                    label_mode='int',\n",
    "                                                    class_names=['PAC'],\n",
    "                                                    batch_size=100,shuffle=True,seed=123,\n",
    "                                                    image_size=(224, 224))\n",
    "image_batch, label_batch = test_dataset.as_numpy_iterator().next()\n",
    "predictions = efficientNet.predict(image_batch)\n",
    "predictions.shape\n",
    "predicted_classes=[]\n",
    "for i in range(100):\n",
    "    predicted_class=np.argmax(predictions[i])\n",
    "    predicted_classes.append(predicted_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0202629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_true=label_batch\n",
    "y_pred=np.array(predicted_classes)\n",
    "confusion_matrix(y_true, y_pred)\n",
    "\n",
    "data = {'y_Actual': y_true,\n",
    "        'y_Predicted': y_pred\n",
    "        }\n",
    "\n",
    "df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\n",
    "confusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "print (confusion_matrix)\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6167c5da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c578cd50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
